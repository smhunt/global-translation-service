DEBUG=true
FRONTEND_URL=http://10.10.10.24:3010

# Whisper settings
# Model: tiny, base, small, medium, large-v2, large-v3
WHISPER_MODEL=base
# Device: cpu, cuda, auto
WHISPER_DEVICE=cpu
# Compute type: int8 (CPU), float16 (GPU), float32
WHISPER_COMPUTE_TYPE=int8

# OpenAI API (for cloud Whisper)
OPENAI_API_KEY=

# Redis for production job storage
# Set USE_REDIS=true to enable Redis storage (recommended for production)
REDIS_URL=redis://localhost:6379
USE_REDIS=false
REDIS_JOB_TTL=3600

# Celery for distributed task processing
# Set USE_CELERY=true to dispatch tasks to Celery workers
USE_CELERY=false
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0
